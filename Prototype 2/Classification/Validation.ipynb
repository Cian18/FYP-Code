{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e4fa1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append(\"C:\\\\Users\\\\Cian\\\\1 FYP Code\\\\Code_with_git\\\\Functions\")\n",
    "from Functions import Bicep_Curl_Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3132c4",
   "metadata": {},
   "source": [
    "I have trained 10 different models, in each model, a different video has been omited from the training data. I will now perform validation (similar to k-fold cross validation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8742b411",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "C:\\Users\\Cian\\Anaconda\\lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 17 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000021CA50F4A60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 17 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000021CA50F4A60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 22 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000021CA6A5C430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 22 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000021CA6A5C430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "for i in range(10):\n",
    "    path = f\"C:\\\\Users\\\\Cian\\\\OneDrive\\\\Documents\\\\Imperial\\\\Year 4\\\\FYP\\\\Local Download\\\\Technical\\\\Bicep Curl Analysis\\\\Classification\\\\Training Data (Videos)\\\\Detailed Exercise Classification\\\\Testing {i}.mp4\"\n",
    "    \n",
    "    model_name = f'Not{i}'\n",
    "    #Now find the predictions for each video based on the model that wasn't trained on it.\n",
    "    result = Bicep_Curl_Classification(path,model_name)\n",
    "    predictions.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea89686",
   "metadata": {},
   "source": [
    "Now import the labels for each video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "694f4a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for i in range(10):\n",
    "    labels.append(np.load(f'C:\\\\Users\\\\Cian\\\\1 FYP Code\\\\Code_with_git\\\\Prototype 2\\\\Classification\\\\Training Data\\\\W=19, Mid Label\\\\Labels{i}.npy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47883a41",
   "metadata": {},
   "source": [
    "Now loop through each set of results to find the following:\n",
    "- Overall accuracy for each class.\n",
    "- Overall accuracy for the whole dataset.\n",
    "- Individual accuracy for each video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a74d91a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cian\\AppData\\Local\\Temp\\ipykernel_32592\\4184390502.py:10: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  acc_0.append(np.sum(label[label==0]==pred[label==0])/len(label[label==0]))\n"
     ]
    }
   ],
   "source": [
    "#initiallize lists that correspond to each class. The accuracy for each video will be appended to these\n",
    "acc_0 = []\n",
    "acc_1 = []\n",
    "acc_2 = []\n",
    "\n",
    "#Now loop through the results from each video\n",
    "for i in range(len(labels)):\n",
    "    label = np.argmax(labels[i],axis=1)\n",
    "    pred = np.argmax(predictions[i],axis=1)\n",
    "    acc_0.append(np.sum(label[label==0]==pred[label==0])/len(label[label==0]))\n",
    "    acc_1.append(np.sum(label[label==1]==pred[label==1])/len(label[label==1]))\n",
    "    acc_2.append(np.sum(label[label==2]==pred[label==2])/len(label[label==2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cac5cce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.990990990990991,\n",
       " 1.0,\n",
       " 0.9166666666666666,\n",
       " 0.9957805907172996,\n",
       " 0.9887005649717514,\n",
       " 1.0,\n",
       " 0.987012987012987,\n",
       " 1.0,\n",
       " nan,\n",
       " nan]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ac45d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy for no curl class =  0.9848939750449619\n",
      "Overall accuracy for concentric contraction class =  0.9228471501024476\n",
      "Overall accuracy for eccentric contraction class =  0.8771041944274343\n",
      "Overall accuracy for whole dataset 0.9282817731916145\n"
     ]
    }
   ],
   "source": [
    "print('Overall accuracy for no curl class = ', np.mean(acc_0[:8]))\n",
    "print('Overall accuracy for concentric contraction class = ', np.mean(acc_1))\n",
    "print('Overall accuracy for eccentric contraction class = ', np.mean(acc_2))\n",
    "print('Overall accuracy for whole dataset', np.mean([np.mean(acc_0[:8]),np.mean(acc_1),np.mean(acc_2)]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
