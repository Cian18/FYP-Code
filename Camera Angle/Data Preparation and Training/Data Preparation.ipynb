{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc048b97",
   "metadata": {},
   "source": [
    "I need to clean this up eventually, I am now back to using 33 landmarks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d355fe81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "from keras.utils import to_categorical\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07795bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"C:\\\\Users\\\\Cian\\\\1 FYP Code\\\\Code_with_git\\\\Functions\")\n",
    "from Functions_Squat import detectPose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16a8819",
   "metadata": {},
   "source": [
    "Import all images that will be used for training. Each class are kept in a single folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18232f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "images = []\n",
    "O = ['Front','Side R', 'Side L']\n",
    "for orient in O:\n",
    "    im = []\n",
    "    i = 1\n",
    "    while True:\n",
    "        path = f\"C:\\\\Users\\\\Cian\\\\OneDrive\\\\Documents\\\\Imperial\\\\Year 4\\\\FYP\\\\Code and Data\\\\Orientation\\\\Training Images\\\\{orient}\\\\1 ({i}).jpg\"\n",
    "        image = cv.imread(path)\n",
    "        # Check if image read successfully\n",
    "        if image is None:\n",
    "            break  # Break the loop if no image is read\n",
    "        im.append(image)\n",
    "        i += 1  # Increment counter for image name\n",
    "    images.append(im)\n",
    "print(len(images))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc61112",
   "metadata": {},
   "source": [
    "Now extract and normalize landmarks for each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31dd4283",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise(image):\n",
    "    # Initialize mediapipe pose class.\n",
    "    mp_pose = mp.solutions.pose\n",
    "    \n",
    "    # Setup the Pose function for images - independently for the images standalone processing.\n",
    "    pose_image = mp_pose.Pose(static_image_mode=True, min_detection_confidence=0.1)\n",
    "    landmarks = detectPose(image, pose_image)\n",
    "    XY = np.array([(landmark.x, landmark.y) for landmark in landmarks])\n",
    "    #only select some landmarks\n",
    "    mask = np.zeros((33),dtype=bool)\n",
    "    #now create a list of numbers that represent the coordinates I want to keep\n",
    "    useful = [11,12,23,24,25,26,27,28]\n",
    "    for i in useful:\n",
    "        mask[i]=True\n",
    "    XY = XY[mask]\n",
    "    \n",
    "    #Now normalize the data. Normalize x coord with respect to the maximum and minimum x coord. Then the same for y.\n",
    "    #Define the maximum and minimum value for x and y coordinates from all landmarks.\n",
    "    xmax = np.max(XY[:,0])\n",
    "    xmin = np.min(XY[:,0])\n",
    "    ymax = np.max(XY[:,1])\n",
    "    ymin = np.min(XY[:,1])\n",
    "    \n",
    "    #normalize the landmarks\n",
    "    X = (XY[:,0]-xmin)/(xmax-xmin)\n",
    "    Y = (XY[:,1]-ymin)/(ymax-ymin)\n",
    "    data = (np.stack((X,Y)).T).reshape(1,16)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b1e135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing class 0\n",
      "Processed image 0 in class 0\n",
      "Processed image 1 in class 0\n",
      "Processed image 2 in class 0\n",
      "Processed image 3 in class 0\n",
      "Processed image 4 in class 0\n",
      "Processed image 5 in class 0\n",
      "Processed image 6 in class 0\n",
      "Processed image 7 in class 0\n",
      "Processed image 8 in class 0\n",
      "Processed image 9 in class 0\n",
      "Processed image 10 in class 0\n",
      "Processed image 11 in class 0\n",
      "Processed image 12 in class 0\n",
      "Processed image 13 in class 0\n",
      "Processed image 14 in class 0\n",
      "Processed image 15 in class 0\n",
      "Processed image 16 in class 0\n",
      "Processed image 17 in class 0\n",
      "Processed image 18 in class 0\n",
      "Processed image 19 in class 0\n",
      "Processed image 20 in class 0\n",
      "Processed image 21 in class 0\n",
      "Processed image 22 in class 0\n",
      "Processed image 23 in class 0\n",
      "Processed image 24 in class 0\n",
      "Processed image 25 in class 0\n",
      "Processed image 26 in class 0\n",
      "Processed image 27 in class 0\n",
      "Processed image 28 in class 0\n",
      "Processed image 29 in class 0\n",
      "Processed image 30 in class 0\n",
      "Processed image 31 in class 0\n",
      "Processed image 32 in class 0\n",
      "Processed image 33 in class 0\n",
      "Processed image 34 in class 0\n",
      "Processed image 35 in class 0\n",
      "Processed image 36 in class 0\n",
      "Processed image 37 in class 0\n",
      "Processed image 38 in class 0\n",
      "Processed image 39 in class 0\n",
      "Processed image 40 in class 0\n",
      "Processed image 41 in class 0\n",
      "Processed image 42 in class 0\n",
      "Processed image 43 in class 0\n",
      "Processed image 44 in class 0\n",
      "Processed image 45 in class 0\n",
      "Processed image 46 in class 0\n",
      "Processed image 47 in class 0\n",
      "Processed image 48 in class 0\n",
      "Processed image 49 in class 0\n",
      "Processed image 50 in class 0\n",
      "Processed image 51 in class 0\n",
      "Processed image 52 in class 0\n",
      "Processed image 53 in class 0\n",
      "Processed image 54 in class 0\n",
      "Processed image 55 in class 0\n",
      "Processed image 56 in class 0\n",
      "Processed image 57 in class 0\n",
      "Processed image 58 in class 0\n",
      "Processed image 59 in class 0\n",
      "Processed image 60 in class 0\n",
      "Processed image 61 in class 0\n",
      "Processed image 62 in class 0\n",
      "Processed image 63 in class 0\n",
      "Processed image 64 in class 0\n",
      "Processed image 65 in class 0\n",
      "Processed image 66 in class 0\n",
      "Processed image 67 in class 0\n",
      "Processed image 68 in class 0\n",
      "Processed image 69 in class 0\n",
      "Processed image 70 in class 0\n",
      "Processed image 71 in class 0\n",
      "Processed image 72 in class 0\n",
      "Processed image 73 in class 0\n",
      "Processed image 74 in class 0\n",
      "Processed image 75 in class 0\n",
      "Processed image 76 in class 0\n",
      "Processed image 77 in class 0\n",
      "Processed image 78 in class 0\n",
      "Processed image 79 in class 0\n",
      "Processed image 80 in class 0\n",
      "Processed image 81 in class 0\n",
      "Processed image 82 in class 0\n",
      "Processed image 83 in class 0\n",
      "Processed image 84 in class 0\n",
      "Processed image 85 in class 0\n",
      "Processed image 86 in class 0\n",
      "Processed image 87 in class 0\n",
      "Processed image 88 in class 0\n",
      "Processed image 89 in class 0\n",
      "Processed image 90 in class 0\n",
      "Processed image 91 in class 0\n",
      "Processed image 92 in class 0\n",
      "Processed image 93 in class 0\n",
      "Processed image 94 in class 0\n",
      "Processed image 95 in class 0\n",
      "Processed image 96 in class 0\n",
      "Processed image 97 in class 0\n",
      "Processed image 98 in class 0\n",
      "Processed image 99 in class 0\n",
      "Processed image 100 in class 0\n",
      "Processed image 101 in class 0\n",
      "Processed image 102 in class 0\n",
      "Processed image 103 in class 0\n",
      "Processed image 104 in class 0\n",
      "Processed image 105 in class 0\n",
      "Processed image 106 in class 0\n",
      "Processed image 107 in class 0\n",
      "Processed image 108 in class 0\n",
      "Processed image 109 in class 0\n",
      "Processed image 110 in class 0\n",
      "Processed image 111 in class 0\n",
      "Processed image 112 in class 0\n",
      "Processed image 113 in class 0\n",
      "Processed image 114 in class 0\n",
      "Processed image 115 in class 0\n",
      "Processed image 116 in class 0\n",
      "Processed image 117 in class 0\n",
      "Processed image 118 in class 0\n",
      "Processed image 119 in class 0\n",
      "Processed image 120 in class 0\n",
      "Processed image 121 in class 0\n",
      "Processed image 122 in class 0\n",
      "Processed image 123 in class 0\n",
      "Processed image 124 in class 0\n",
      "Processed image 125 in class 0\n",
      "Processed image 126 in class 0\n",
      "Processed image 127 in class 0\n",
      "Processed image 128 in class 0\n",
      "Processed image 129 in class 0\n",
      "Processed image 130 in class 0\n",
      "Processed image 131 in class 0\n",
      "Processed image 132 in class 0\n",
      "Processed image 133 in class 0\n",
      "Processed image 134 in class 0\n",
      "Processed image 135 in class 0\n",
      "Processed image 136 in class 0\n",
      "Processed image 137 in class 0\n",
      "Processed image 138 in class 0\n",
      "Processed image 139 in class 0\n",
      "Processed image 140 in class 0\n",
      "Processed image 141 in class 0\n",
      "Processed image 142 in class 0\n",
      "Processed image 143 in class 0\n",
      "Processed image 144 in class 0\n",
      "Processed image 145 in class 0\n",
      "Processed image 146 in class 0\n",
      "Processed image 147 in class 0\n",
      "Processed image 148 in class 0\n",
      "Processed image 149 in class 0\n",
      "Processed image 150 in class 0\n",
      "Processed image 151 in class 0\n",
      "Processed image 152 in class 0\n",
      "Processed image 153 in class 0\n",
      "Processed image 154 in class 0\n",
      "Processed image 155 in class 0\n",
      "Processed image 156 in class 0\n",
      "Processed image 157 in class 0\n",
      "Processed image 158 in class 0\n",
      "Processed image 159 in class 0\n",
      "Processed image 160 in class 0\n",
      "Processed image 161 in class 0\n",
      "Processed image 162 in class 0\n",
      "Processed image 163 in class 0\n",
      "Processed image 164 in class 0\n",
      "Processed image 165 in class 0\n",
      "Processed image 166 in class 0\n",
      "Processed image 167 in class 0\n",
      "Processed image 168 in class 0\n",
      "Processed image 169 in class 0\n",
      "Processed image 170 in class 0\n",
      "Processed image 171 in class 0\n",
      "Processed image 172 in class 0\n"
     ]
    }
   ],
   "source": [
    "Data = []\n",
    "\n",
    "# Loop through each class of images\n",
    "for i, class_images in enumerate(images):\n",
    "    norm_landmarks = []\n",
    "    print(f\"Processing class {i}\")\n",
    "    \n",
    "    # Loop through each individual image\n",
    "    for j, img in enumerate(class_images):\n",
    "        try:\n",
    "            # Extract and normalize all landmarks, then reshape into a vector (ready for the neural net).\n",
    "            norm_landmarks.append(normalise(img))\n",
    "            print(f\"Processed image {j} in class {i}\")\n",
    "        except Exception as e:\n",
    "            # Print an error message and continue with the next image.\n",
    "            print(f\"Skipping image {j} in class {i} due to error: {e}\")\n",
    "\n",
    "    Data.append(np.stack(norm_landmarks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f017ac33",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = []\n",
    "Data.append(np.load(\"C:\\\\Users\\\\Cian\\\\1 FYP Code\\\\Code_with_git\\\\Prototype 3\\\\Camera Angle\\\\Training Data\\\\Front.npy\"))\n",
    "Data.append(np.load(\"C:\\\\Users\\\\Cian\\\\1 FYP Code\\\\Code_with_git\\\\Prototype 3\\\\Camera Angle\\\\Training Data\\\\SideR.npy\"))\n",
    "Data.append(np.load(\"C:\\\\Users\\\\Cian\\\\1 FYP Code\\\\Code_with_git\\\\Prototype 3\\\\Camera Angle\\\\Training Data\\\\SideL.npy\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcb1eba",
   "metadata": {},
   "source": [
    "Now create the Labels.\n",
    "- [1,0,0] = Forward Facing\n",
    "- [0,1,0] = Side Right\n",
    "- [0,0,1] = Side Left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2cbfbe45",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [0]*len(Data[0])+[1]*len(Data[1])+[2]*len(Data[2])\n",
    "labels = to_categorical(labels,3)\n",
    "\n",
    "#Concatenate the data into a single array\n",
    "data = np.concatenate(Data)\n",
    "\n",
    "#Now shuffle both the data and the labels\n",
    "perm = np.random.permutation(len(labels))\n",
    "data = data[perm]\n",
    "labels = labels[perm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9a91f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the labels and the data\n",
    "np.save(\"C:\\\\Users\\\\Cian\\\\1 FYP Code\\\\Code_with_git\\\\Prototype 3\\\\Camera Angle\\\\Training Data\\\\Data.npy\",data)\n",
    "np.save(\"C:\\\\Users\\\\Cian\\\\1 FYP Code\\\\Code_with_git\\\\Prototype 3\\\\Camera Angle\\\\Training Data\\\\Labels.npy\",labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
